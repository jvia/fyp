#+title:     Final-Year Project
#+author:    Jeremiah Via
#+email:     jeremiah.via@gmail.com
#+options:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t
#+options:   TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:not-in-toc
#+infojs_opt: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+startup: hidestars indent

1. (λ mnfx . (n (m f)) x) (λ fx . f (f x)) (λ fx . f (f (f x)))
2. λ mnfx . (n ((λ fx . f (f x)) f)) x) (λ fx . f (f (f x))
3. λ mnfx . ((λ fx . f (f (f x))) ((λ fx . f (f x)) f)) x
4. λ mnfx . ((λ fx . f (f (f x))) (λ x . f (f x))) x
5. λ mnfx . ((λ fx . f (f (f x))) ) x

* Project
** DONE Find class where calculation takes place
org.bham.aucom.fts.tranform.CalcEntropyAvgScore

T2GramModelTrainer
** DONE Make a simple 3-component chain
** TODO Get data running on 3-chain
** TODO Get data with 3-chain taking connections into account
* Logbook

Weekly logs from the project.

** 2011-10-03

   - Dora experiments

** 2011-10-10

I investigated how I will publish message signatures from ROS to
aucom and my system. At first, I looked at using Java since writing
a networking client is something I know how to do. Unfortunately,
significant portions of rosjava are unimplemented (and without any
mention in the documentation). I next considered Python, since it
is probably the most tightly integrated language into ROS. There
are a lot of ways to access the Master node, but after reading more
documentation, I saw that the Master node simple helps other nodes
find each other. After the connection is made, all communication is
peer-to-peer. This seriously threw a wrench in my plans for
automatic publishing of all topics.

After more consideration, I decided to only listen to topics
provided by a configuration file or commands line argument. This is
probably the better approach, because a learned model can work on
only part of the system. There is still the tricky bit of taking
this list, importing all of the relevant msgs, and then registering
a separate callback function for each event type. There are a
number of ways to solve this: 1) Use Lisp macros to generate
callback functions at runtime. This could be pretty simple since
the callback only has to do something like

#+BEGIN_SRC lisp
     (publish timestamp topic-name topic-type)
#+END_SRC

which would be easy to generate as a macro. Other approaches are
not likely to be as nice as this one.

--------

I met with Peter Tino for advice about using a neural network to
classify system state.  He told me not to necessarily limit myself
to using a neural network, as there might be other approaches that
could work more easily. Some examples he mentioned were one-class
learning, support vector machines, and a graph kernel. I will have
to look into these approaches. He stressed that the most important
thing I have to figure out is how to represent the data. Temporal
data is complex and I must spend time figuring out a representation
from which I can learn.

** 2011-10-17

Met with Nick & Marc this week and got some brief feedback
regarding my project proposal. Marc said I should have been more
explicit in my time line, in that the events I listed on my Gantt
chart are not specific enough for someone who is not me, because
they won't know what these events mean. Ela commented that I did
not determine my criteria for success, which is an excellent point
I had not considered. Marc said that I should avoid selecting any
criteria that can be answered with a yes or no question. Rather, I
should select criteria which allows me to compare on multiple
dimensions.

** TODO 2011-10-24
** TODO 2011-10-31
** TODO 2011-11-07
** TODO 2011-11-14
** TODO 2011-11-21
** TODO 2011-11-28
** TODO 2011-12-05
** 2012-01-09
*** Wednesday

Started worked on ROS-CAST connection. I created all of the
necessary classes and now I need to fill in the method stubs.

*** Thursday

Met with Nick today. We talked about the project and which direction
to head. Some of the things we talked about:

- Heart beat
  - what can it be used for
  - limitations on training and testing
- What kind of variations in training can aucom take?
  - Flat curve, i.e., random events like faces cannot be predicted

An important point he mentioned was what kind of story I want to tell
with my project. I need to provide a deeper understanding and go
beyond what Raphael, i.e., don't just implement on other systems.

He suggested that I start from the beginning so I can find a goal for
aucom. I should determine what it can and cannot do and relate these
to real-life scenarios. Essentially, I need to find the story that
says "his system can't do X, this is how we extended it so it could do
X".

An interesting problem is determining how well the system scales.

** 2012-01-16

Quantitative:

- Determine memory & cpu
- compare to score
- experiments on the score

Qualitative:
- What changes by doing it this way?
- Is there anything I may lose, however subtle?

Is it even possible to model the numbers across new chains?


3-chain run with dynamic start, i.e., start t random times and see how
it effects the scoring over time.

Overall testing:
- Wireless connectivity (throttling network connectivity)
- Camera lead falls out
- Component lockup


coding:
- set non-conecteds ones to 0
- thrn try bigger change

** 2012-01-23
*** FYP Talk: Evaluating Software

- How well does the project meet the spec?

- How systematic has evaluation been?

- Have a section & break it up into quantitative analysis &
  qualitative analysis.

- Evaluating the process
  - the design decision made along the way
  - need to justify the steps taken

- Need to identify differences between other approaches, i.e., prior
  techniques.

- *Qualitative analysis*
  - How could the end user receive this?
  - Focus on feature analysis on finished project.
  - Case studies? Hard to replicate, but used to evaluate
    scalability. 

- *Literature review*
  - Appears in background but can also be used to in evaluation by
    comparing features.
  - Be ethical & honest.
  - There is always some delta by which to compare.

- *Feature analysis*
  - List all features & define them with a scale
  - Evaluate this software against features.
  - Document for evaluation on FYP website.

*** Observations

0.1 seems a good cutoff

The model is represented as a matrix of probability
distributions. What is a good way to model "empty" for a probability
distribution? I don't think there is one.

** 2012-01-30
*** Meeting with Nick

Key questions I need to answer:
- What can I show different between the two?
- Where and how will differences manifest?

I need to create systems that test the algorithm and ones that are
necessarily faithful to a real system. It's more important to find the
limits of the algorithm.

Main goal: results! I need to create graphs to compare
performance. This is of critical importance!

*** Talk with Raphael

Experiments worth conducting for Raphael:
- Component crash
- Resource starvation

Experiments to test the algorithm:
- Really long chains
- Many disjoint chains
- Tons of individual components

Score does not change because there is a bug in the system right now.

** COMMENT 2012-02-06
** COMMENT 2012-02-13
** COMMENT 2012-02-20
** COMMENT 2012-02-27
** COMMENT 2012-03-05
** COMMENT 2012-03-12
** COMMENT 2012-03-19
* COMMENT Appendix

#  LocalWords:  SRC Gantt Ela
