#+title:
#+author:  Jeremiah M. Via
#+options: H:4 num:t toc:nil \n:nil @:t ::t |:t ^:nil -:t f:t *:t <:t
#+options: TeX:t LaTeX:t skip:nil d:nil todo:t pri:nil tags:nil
#+startup: hidestars indent
#+INFOJS_OPT: view:nil toc:nil ltoc:t mouse:underline buttons:0 path:http://orgmode.org/org-info.js
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+LATEX_CLASS: dissertation
#+LATEX_CLASS_OPTIONS: [a4paper,oneside,12pt,onecolumn,final,openany]
#+LATEX_HEADER: \usepackage{algorithmic}
#+LATEX_HEADER: \usepackage{algorithm}
#+LATEX_HEADER: \usepackage{program}
#+LATEX_HEADER: \usepackage{appendix}
#+LATEX_HEADER: \usepackage[section]{placeins}
#+LATEX_HEADER: \usepackage{subfig}
#+LATEX_HEADER: \NumberProgramstrue
#+LATEX_HEADER: \linespread{1.3}

######################################################################
# Title page
######################################################################
#+begin_latex
\begin{titlepage}
%% Set the line spacing to 1 for the title page.
\begin{spacing}{1}
\begin{large}
\begin{center}
\mbox{}
\vfill
\begin{sc}
A Data-Driven Self-Awareness Model for Robotics Systems \\
\end{sc}
\vfill
Jeremiah M. Via \\
Supervisor: Nick Hawes \\
\vspace*{4mm}
\includegraphics[width=50mm]{crest.png}\\
Submitted in conformity with the requirements\\
for the degree of Artificial Intelligence \& Computer Science\\
School of Computer Science\\
University of Birmingham\\
\vfill
Copyright {\copyright} 2012 School of Computer Science, University of Birmingham\\
\vspace*{.2in}
\end{center}
\end{large}
\end{spacing}
\end{titlepage}
#+end_latex

######################################################################
# Abstract
######################################################################
#+begin_latex
\thispagestyle{empty}
\newpage
\setcounter{page}{1}
\pagenumbering{roman}

\begin{abstract}
Fault-detection in robotics systems is a difficult task. As robotics
systems are becoming larger and more complex, subtle errors are
becoming harder to detect and diagnose. Traditional fault-detection
approaches have relied on explicit modeling of component behavior,
either quantitatively or qualitatively, but these techniques will
not scale to complex robots operating in dynamic environments.
Machine learning approaches have become one way to overcome this
limitation. A new technique which involves making the robot
self-aware to the internal state of its own components is examined.
This project implements and then measures the efficacy of a
probabilistic self-awareness model for event-based robotics
middlewares. Alternative model formulations are proposed and
examined experimentally and asymptotically as a way to deal with
shortcomings of the original approach.

\vspace{0.5cm}
\noindent\textit{Keywords}: robotics, fault detection,
machine learning
\end{abstract}
\newpage
#+end_latex

######################################################################
# Acknowledgments
######################################################################
#+begin_latex
\renewcommand{\abstractname}{}%{Acknowledgments}
\begin{abstract}
To Nick, Marc, and Raphael for guiding me on the first project of my
scientific career.
\end{abstract}
\newpage
#+end_latex

######################################################################
# TOC
######################################################################
#+begin_latex
\tableofcontents
\newpage

\setcounter{page}{1}
\pagenumbering{arabic}
#+end_latex

* Motivation                                                          :PASS1:
\label{sec:motivation}

The number and uses of robots is increasing. More and more robots are
becoming part of the daily human experience. There are robots in
factories automating difficult, repetitive tasks. There are an
increasing number of domestic robots being used for assistance in the
home and as entertainment. There are even robots being used as
surgical tools, allowing doctors to perform surgery more safely. It is
important for these robots to function correctly, and if unable to do
so, for them to degrade gracefully to minimize harm to themselves and others.
To do this, robots need some way to determine their own operating
conditions. Detecting faults within robotics systems is a hard
problem.

The importance of equipping a robot with the ability of self-awareness
increases as humans interact more with robots. One could imagine a
domestic robot which assisted an elderly person with chores around the
home or a robot performing heart surgery. A malfunction in these
situations could cause death or serious injury. One could also imagine
robotic arms at a factory building cars where a malfunction could
cause damage to products, or the arm itself, resulting in a loss of
factory output. These examples underscore the importance of detecting
and handling faults within a robot system.

This project was conducted in collaboration with Raphael Golombek at
Bielefeld University who first implemented this technique on the XCF
middleware \cite{Wrede:2004th}. The main goal for the project was to
take Raphael's software, modify it to work with the robotics
middleware used at the Univeristy of Birmingham---the CoSY
Architecture Schema Toolkit (CAST) \cite{haweswyatt10aei}---and
determine its efficacy. The impetus for this project was to see if the
technique developed by Raphael could work on another middleware. To
determine the efficacy of this approach, a number of experiments were
conducted to test the algorithm's capabilities. With the time
available after the completion of the main project component, the
scalability of the learned model was examined and alternative
formulations proposed.

The rest of the dissertation is organized into six main sections. It
will begin with a literature review which will give a brief overview
of techniques used by others who have attempted to solve this problem.
The literature review will also show where the technique presented in
this dissertation fit with previous techniques. Following on from the
literature revew, the theory section will cover the necessary
background needed to understand the technique presented in
\cite{Golombek:2011ek}. This section should give the reader enough
understanding to implement the technique on any event-based robotics
middleware. After an explanation of the theory, a section will cover
its implementation on CAST. This section will also give some
experimental results as well as asymptotic analysis of the key
portions of the technique. The asymptotic analysis will be an
important motivation for the alternative model formulations presented
in later sections. After covering the original implementation and its
analysis, the next few sections will cover alternative formulations of
the learned model, experimental results, as well as asymptotic
analyses of these alternative models. The differences between these
model formulations and the trade-offs required will be discussed.
Finally, the last few sections will cover project management and
present an evaluation of the project.

* Literature review                                                   :PASS1:
\label{sec:lit-review}

Detecting faults and closing-the-loop has received considerable
attention since at least the 1980s \cite{deKleer:1987vc}, although not
necessarily on robots. There are two main approaches to solving this
problem: model-based and data-driven. Model-based approaches have come
from traditional engineering disciplines and are created through
exhaustive specification of component behavior. Data-driven approaches
are newer and leverage machine learning techniques.

There exists two styles within the domain of model-based approaches.
The first is the analytical approach which is used in problems which
are close to the hardware. They depend on a set of assumptions,
rigorous specification, and testing \cite{blanke2006}. These
analytical approaches also require the creation of recovery routines
for all possible faults. Because this approach is so tedious, work has
been made on trying to combine data-driven approaches with analytical
approaches \cite{Luo:2010ud}. The second is the knowledge-based
approach where qualitative models are used. A popular method has been
consistency-based diagnosis \cite{deKleer:1987vc}, which often make
use of propositional logic. There has been much work using this idea
on diagnosis engines such as Livingstone
\cite{Kurien:2000ta,Williams:1996wf}, HyDE \cite{Narasimhan:2007ty},
and Lydia \cite{Feldman:2010uy}. The Livingstone has been very
successful, having been used on /Deep Space One/ \cite{Bajwa:2002tm},
/Earth Observing One/ \cite{Hayden:2004vn}, and on the /Autosub 6000/
\cite{Ernits:2010tm}. Unfortunately, model-based approaches are suboptimal for
complex robotics systems due to fact that explicit modeling of all
component interactions is required. This modeling requires expert
knowledge of all components in the robotics system.

Data-driven approaches have used machine learning in an attempt to
bypass the effort involved with model-based approaches. A wide variety
of approaches have been tried, broadly categorized as deterministic
and stochastic \cite{Golombek:2011ek}. Deterministic approaches have
generally attempted to cluster the feature space to separate normal
classes from faulty ones \cite{DeStefano:2000vt,Chandola:2006um}.
Stochastic techniques have assumed that anomalous data points would be
in low probability areas \cite{Casar:2008tp,Ye:2000uu}. The idea then
is to use statistical inference on model which has been fit to
previously gathered data. Generally, the deterministic approaches have
failed to handle the uncertainty present in the complex systems in
robots.The stochastic approaches previously mentioned have depended on
the Markov assumption which does not hold in the complex communication
patterns in a robot \cite{Golombek:2010hj}.

The method used in this project was first described in
\cite{Golombek:2010hj} and \cite{Golombek:2011ek}. It is a purely
data-driven approach which finds structure in the temporal-stream of
communication between software components in a complex robotics
system. The original system was developed to work with the XCF
middleware and for this project has been extended to work the CAST
middleware.

* Theory                                                              :PASS1:
\label{sec:theory}

#+begin_latex
\begin{wrapfigure}{R}{0.61\textwidth}
\centering
\includegraphics[width=0.6\textwidth]{img/simple.pdf}
\caption[A simple system]{This example shows a system at three discrete points in time and how data flows through a system. Notice that a message event occurs at a point in time. The goal is to exploit this knowledge to learn a model.}
\label{fig:simple}
\end{wrapfigure}
#+end_latex

Before we proceed, it is useful to define some vocabulary. The
vocabulary intends to be independent of the terminology of any
specific middleware and will instead focus on intuitive words to better
explain the theory. This technique aims to detect faults in software
and so all discussion will implicitly be in this domain unless otherwise
specified. We will consider the whole of a robot's software a system
which is divided into a set of components. Each component does some
job (e.g., a component which takes in laser and map data to determine
the robot's location) and the coordination of multiple components is
used to solve some task. Components will be said to subscribe and
publish to one another. If component /A/ subscribes to component /B/,
component /A/ will received all messages published by component /B/.
When a component publishes a message, it is considered an event. These
messages are typed, so, returning to the example of a localizing
component, its message type might be the coordinates required to
describe its position in configuration space. Events also have a
type: the metadata required to describe a component, its location in a
robotics system, and the message type. This is necessary because a
component can publish more than one message type and more than one
component can publish the same message type. With this requisite
vocabulary, a formal description of the theory will follow.

The main hypothesis of this approach states that a robotics system is
a set of communicating components which generate temporal
communication patterns when accomplishing tasks. These temporal
communication patterns exhibit structures which depend on the current
state of the robot \cite{Golombek:2010hj}. Because this approach uses
a machine learned model, it falls completely within the data-driven
approach to fault detection as described in section
\ref{sec:lit-review}. The goal of this technique is to exploit the
latent temporal-structure within the observed communication stream to
learn a pattern of communication which correlates with normal system
behavior.

In order to classify the robot as being in a normal or faulty state, a
score is calculated against the learned model. This model represents
the pattern of communication during normal system behavior. More
specifically, the model represents the expectation of the time between
publication events between all event types. Once the score is
calculated, it is compared against a moving threshold to create the
classification of the robot's state at any given time.

######################################################################
# Introduce the example to be used in explaining the idea
######################################################################

To ground the discussion, a simplistic example is shown in figure
\ref{fig:simple}. This graph represents a set of three components and
how messages pass through the system. These components can be seen as
chained together n a linear communication pattern. In this example,
node /A/ publishes message /a/ at timestamp $t$ which passes to node
/B/. Node /B/, after doing some arbitrary computation, publishes a
message /b/ at timestamp $t'$ which is passed to node /C/. So, in this
example, a message event occurs at 100 milliseconds which could be
encoded as =A:a:100ms= and a message event occurs at 150
milliseconds which could be encoded as =B:b:150ms=. It is not
necessary that data flow linearly through a system. In general,
real-life robotics systems exhibit more complicated inter-component
communication patterns. Figure \ref{fig:complex} shows a more complex
system in which components publish multiple messages types and
subscribe to multiple components.



#+begin_latex
\begin{wrapfigure}{L}{0.41\textwidth}
\centering
\includegraphics[width=0.4\textwidth]{img/complex.pdf}
\caption[A complex system]{In a real system, data flow will likely be non-linear.}
\label{fig:complex}
\end{wrapfigure}
#+end_latex

The rest of this section will use figure \ref{fig:simple} as a simple
example for illustrative purposes. First, the idea and creation of the
learned model will be explained, followed by the calculation of the
score, and then the calculation of the final classification.

** Learning the model                                                :PASS1:

The learned model exploits the hypothesis that a robot composed of a
set of software components exhibits temporal communication patterns
and that these patterns exhibit different structures depending on the
state of the robot. The goal then becomes to learn the inter-component
communication patterns when the robot is functioning correctly. With
this model, the robot's state can be classified depending on how
closely its current communication pattern adheres to the learned
communication pattern. If the current pattern deviates too far from
the learned pattern, then the robot can be said to be in an anomalous
state. The first step is to create the learned model.

#+begin_latex
\begin{wrapfigure}{l}{0.41\textwidth}
\centering
\includegraphics[width=0.4\textwidth]{img/learned.pdf}
\caption{A distribution is learned for each pair of event types.}
\label{fig:learned}
\end{wrapfigure}
#+end_latex

The model is learned by collecting an observation time-series and
learning how components publish with respect to one another. More
formally, let $E$ be the set of an encoded time-series of component
communication data which is recorded during normal operation. For each
tuple $(e_i,e_j) \in E \times E$, a probability distribution $P_{ij} =
P(t \vert e_i,e_j)$ is estimated. The distribution $P_{ij}$ represents
the expected timespan of event $e_j$ occurring after event $e_i$. The
event $e_i$ is constrained to be the last seen occurrence of this
event type because the goal is to model temporal correlations between
the current event and the last seen occurrence of a given event type.
Learning the model for the example present back in figure
\ref{fig:simple}, results in a matrix of distributions as shown in the
matrix in \eqref{matrix:ex1}.

\begin{equation}
\label{matrix:ex1}
\begin{bmatrix}
P_{aa} & P_{ab} & P_{ac}\\
P_{ba} & P_{bb} & P_{bc}\\
P_{ca} & P_{cb} & P_{cc}
\end{bmatrix}
\end{equation}

To be clear, the model does not learn transition times between sets of
connected components, but instead learns the likelihood of the
time-span between the publication of message events of any two
components, even those which never directly communicate within the
system.

The estimation of $P_{ij}$ makes use of a Kernel Density estimator
which has been initialized with a Gaussian Kernel $K(u) =
\frac{1}{2\pi}e^{-\frac{1}{2}u^2}$ \cite{Golombek:2011ek}. The set of
all learned distributions becomes the model $\mathcal{M} = \{P_{ij}
\vert (e_i,e_j) \in E \times E\}$. $\mathcal{M}$ is now the matrix
shown in \eqref{matrix:ex1}. Figure \ref{fig:learned} makes clear that
a distribution is learned for the Cartesian product of the set of
event types.

** Calculating the score                                             :PASS1:

During a live run, the score is calculated by comparing the incoming
stream of communication (i.e., message events) to the learned model.
The score is higher the more closely the incoming pattern
matches the learned pattern. Formally, the score at event $e_j$ is
defined as

#+begin_latex
\begin{equation}\label{eq:score}
s_j = \sum_{e_i \in E} w_{ij} \cdot P_{ij}(\Delta{}t_i)
\end{equation}
#+end_latex

\noindent where $E$ is the set of last seen instances of each event
type and $w_{ij}$ is the relative weighting of the probability value.
The weight $w_{ij}$ is a measure of how meaningful the particular
distribution $P_{ij}$ is as an indication to the system's performance.
The weight is defined as

#+begin_latex
\begin{equation}\label{eq:weight}
w_{ij} = 1 - \frac{h_{ij}}{\sum_{e_i \in E} h_{ij}}
\end{equation}
#+end_latex

The weight calculation presented in equation \eqref{eq:weight} makes
use of the entropy of the distribution. This represents how much
information is contained in a particular distribution and is used as a
measure of trustworthiness. Essentially, the lower the entropy, and
thus the more information contained in the distribution, the more
willing we are to trust the correlation between the two event types.
An algorithm for calculating the score is presented in algorithm
\ref{alg:score}.

#+begin_latex
\begin{algorithm}
\caption{Calculating the score on the receipt of event $e_j$ with
the set E of last seen instances of all event types.}
\label{alg:score}
\begin{program}
\FUNCT |score|(e_j, E) \BODY
s \gets \sum_{e_i}^E (1 - \frac{h_{ij}}{H_j}) P_{ij}(\Delta(e_i,e_j))
|return | \lVert s \rVert
\WHERE
h_{ij} \equiv \text{ entropy of } P_{ij}
H_j    \equiv \text{ sum entropy of } P_{*j}
\Delta(i,j) \equiv \text{ timespan between events $i$ and $j$}
\END
\end{program}
\end{algorithm}
#+end_latex

** Calculating the threshold                                         :PASS1:

An important aspect of this technique is that as the score changes
over the course of a system run so does the threshold. What is
considered the threshold for normal behavior is dependent on the
consistency of the communication pattern within the system. The
threshold changes according to formula \eqref{eq:threshold}. The idea
behind this formula is that the variance $S_{var}$ of consecutive scores
$S = (s_1, \dotsm, s_{j-1}, s_j)$ is lower when events match the
normal pattern learned in the model $\mathcal{M}$. So, when the
variance is lower, and thus the events better match the learned model,
the threshold is lowered. If the score variance increases, the
threshold increases as well to make the threshold harder to exceed.
This formula is defined formally as

#+begin_latex
\begin{equation}\label{eq:threshold}
s^* = a \cdot s^*_{val} + (1 - a) \cdot s^*_{val} \cdot \frac{S_{var}}{s^*_{var}}
\end{equation}
#+end_latex

where $S_{var}$ is the score variance, $s^*$ is the threshold
variance, and $s^*_{val}$ is a constant minimum threshold which is
determined before runtime.

** Classifying the system                                            :PASS1:

With the score and threshold calculated, classifying the system is
straight forward. As can be seen in \eqref{eq:classification}, the
system is considered abnormal anytime the score of the current event
$e_j$ does not exceed the calculated threshold $s^*$.

#+begin_latex
\begin{equation}\label{eq:classification}
\text{abnormal}(e_j) = \begin{cases}
&\text{true}  : s_j < s^*\\
&\text{false} : else
\end{cases}
\end{equation}
#+end_latex

* Original system                                                     :PASS1:
** Implementation                                                    :PASS1:

To implement the technique first specified by \cite{Golombek:2010hj}
on CAST, it was necessary to modify the code first implemented by the
original author and create a CAST component to connect to the modified
source. This section will cover the changes made to the original
source, and the background knowledge to put it into context, as well
as the description of the CAST component.

#+begin_latex
\begin{wrapfigure}{R}{0.41\textwidth}
\centering
\includegraphics[width=0.4\textwidth]{img/fts.pdf}
\caption[The FTS graph processor]{The main steps shown in the FTS processing graph representation. Decomposing problems this way allows for high code re-use.}
\label{fig:fts}
\end{wrapfigure}
#+end_latex

The original system created at Bielefeld was implemented using the
Filtering, Transformation, and Selection Library (FTS)
\cite{Lutkebohle:2009vy}. Using FTS, one decomposes a problem into a
set of nodes which process data in discrete steps. This technique
allows for increased code re-usability due to the fact that nodes can
be connected any number of ways. By modifying the nodes and their
connections, the original implementation was modified to use CAST as
the data source instead of the XCF middleware.

In a CAST system, tasks are solved by a set of components grouped into
subarchitectures. Components communicate to one another through a
working memory local to the subarchitecture. Additionally, any
inter-subarchitecture communication also occurs through working
memories. A full explanation of CAST can be found in
\cite{haweswyatt10aei} but is beyond the scope of this dissertation. A
CAST component was created to monitor changes to any working memory
within the system. If a change was detected, metadata about the
message event was created and sent over a network connection to the
fault-detection system. The CAST component could additionally receive
the classification status back from the fault-detector for use by
other components but this scenario was never explored.

** Experimental results                                              :PASS1:

In order to evaluate the system, a series of experiments were created
to test the algorithm. Three different CAST systems were created, each
with properties to challenge the algorithm (and the changes made to it) in
some way. In each of the following experiments, each component
publishes only a single event type. The following sections will
present the systems tested, the methodology used, and the results of
the experiments.

*** Systems

- Linear chain system :: This is the simple system presented as an
     example back in section \ref{sec:theory} and was used as a sanity
     check when running experiments.
- Parallel chains system :: This system is a more complex version of
     the linear chain system. It is four independent, linear systems.
     The goal with this system was to test how independent chains of
     message events would affect one another and how the technique
     would handle disturbances.
- Non-connected system :: This system had ten unconnected components.
     It was created as an edge case to test the ability of the
     algorithm. It is worth noting that this system does not
     represent a realistic system for solving a task in an event-based
     architecture.

*** Methodology
\label{subsubsec:experiment_methodology}

The experiments were run in a virtual machine with each system being
run ten times. During the first phase, four-thousand message events
are collected from a normal run of this system. It is this data that
will be used to train the model that is used in the ten runs. In the
second phase, the system is run for another four-thousand message
events with a fault being induced at the two-thousand message event
mark. The performance is analyzed by calculating the delay between
fault induction and fault detection, the sensitivity and
specificity of the fault detector, and the Matthews correlation
coefficient.

The delay between fault induction and fault detection tells us how
quickly the algorithm can detect a fault within the system. The goal
is to detect a fault as quickly as possible. The sensitivity indicates
the likelihood that the fault detector will classify a fault as being
a faulty state. The specificity indicates the likelihood that a normal
state will be correctly classified. The Matthews correlation
coefficient (MCC) is measure of the agreement between predicted state and
observed state. If the MCC value is +1, it indicates perfect
prediction; if -1, it indicates total disagreement; and if 0, it
indicates random prediction \cite{Baldi:2000wp}.

Graphs for all experiments can be found in appendix
\ref{append:graphs}.

*** Results

#+caption: Experimental results from the original algorithm.
#+attr_latex: align=|l|r|r|r|r|
#+label: tbl:original
|---------------+-------------+-------------+------+-----------|
|               | Sensitivity | Specificity |  MCC | Delay     |
|---------------+-------------+-------------+------+-----------|
| Linear        |         1.0 |         1.0 |  1.0 | 0.37 sec. |
|---------------+-------------+-------------+------+-----------|
| Parallel      |         1.0 |        0.90 | 0.92 | 0 sec.    |
|---------------+-------------+-------------+------+-----------|
| Non-connected |        0.99 |        0.94 | 0.96 | 0.50 sec. |
|---------------+-------------+-------------+------+-----------|

Table \ref{tbl:original} summarizes the results of the experiments.
The original approach had nearly perfect sensitivity in all
experiments meaning correct classification occurred during almost the
entirety of the faulty system state. The specificity is also high
which means that few false alarms were signalled during the run. This
is a desirable property because fault recovery routines could be
costly with respect to a robot's task goal. The MCC value indicates
that the fault detector prediction almost perfectly matched the ground
truth in all experiments. All faults were detected in less than half
of a second. To be clear, the reason why there is a delay and perfect
sensitivity in the linear experiment is due to the fact that there is
a delay in the calculation of the score. The first system
classification value after the fault was induced was faulty, but it
took 0.37 seconds for this classification to occur. The approach was
least performant on the non-connected component system. This was
because there is less information in the interaction between
components for the model to contain and as a result, when one
component was killed the score did not change much.

** Asymptotic analysis                                               :PASS1:
\label{subsec:orig-asymp}

When evaluating the approach first described in
\cite{Golombek:2010hj}, beyond knowing how it performed
experimentally, it was also desirable to know how the algorithm would
scale with input. This is done by performing asymptotic analysis of
the technique. It is the learned model which is truly core to this
approach and so analysis will focus on the model. There are two
aspects worth analyzing: the runtime efficiency score calculation from
the model and the space efficiency of the model itself.

Space efficiency is concerned with analyzing the amount of memory an
algorithm utilizes as input grows. In the approach described in
section \ref{sec:theory}, we saw that the algorithm learns a
probability distribution for the Cartesian product of the set of event
types. Because this value is constant, we can represent it formally as

\begin{equation}\label{eq:orig_memory}
\text{model}(n) \in  \Theta(n^2)
\end{equation}

This means that as the number of event types $n$ increases, the size
of the model must grow quadratically. During experimentation, it was
observed that with a system of 100 components, memory usage had
exceeded 4 GB. This would become a major concern on a system like the
Asimo which, due to its behavior-based architecture, runs hundreds of
components at a time \cite{Sakagami:2002cf}.

The runtime efficiency of score calculation was another area of
concern because this algorithm depended directly on the size of the
model. The calculation is off of the algorithm
\ref{alg:score} from section \ref{sec:theory}. On analysis, we can see
that there are two aspects to the algorithm: calculating the sum
entropy and then calculating the whole score which can be seen in
equation \eqref{eq:orignal_score}.

#+begin_latex
\begin{equation}
\label{eq:orignal_score}
\begin{split}
score(n) &= H_{ij} + \sum_{e_i}^E\\
score(n) &= n + 5n\\
score(n) &= 6n\\
score(n) &\in \Theta(n)
\end{split}
\end{equation}
#+end_latex

Since the sum entropy $H_j$ will be the same for all events $e_i \in
E$ on the receipt of event $e_j$, this only needs to be calculated
once. Calculating this value requires a simple summation over the $n$
entries which have information about the event type $j$, hence its
value is $n$. Similarly, the score calculation is a summation over the
$n$ relevant entries in $E$ with the addition of five steps for each
entry, hence $5n$. Performing arithmetic, we can see that while the
model may be $\Theta(n^2)$, the score calculation is only $\Theta(n)$
because it only considers the relevant entries.

* Connection-based model                                              :PASS1:
** Idea & Implementation                                             :PASS1:

The asymptotic analysis from section \ref{subsec:orig-asymp} showed
that the space efficiency of the learned model could not scale with
larger systems and provided motivation for alternative model
formulations. The goal for the rest of the project then became to find
a way to reduced the size of this model. The initial idea was to use
the information about the connections between components---all
information which could be gathered /a priori/ on CAST
\cite{Otto:2010uc}. This information could then be exploited to prune
the model and retain only the parts of the model which correlate to
actual paths of communication within the real system.

Using the example presented in figure \ref{fig:simple}, we can see
that informaton flows from node /A/ to node /B/ and from node /B/ to
node /A/. Using the idea of pruning, we could remove from the model
the learned distributions between components /A/ and /C/. Additionally,
since information in this example flows as a directed graph, we can
prune all distributions which correlate to the reverse direction,
e.g., $P_{ab}$. It was decided that the distribution which modeled a
component to itself would be kept because it would be useful to have a
distribution of how often a component published. All together, the model
$\mathcal{M}$ is reduced to

#+begin_latex
\begin{equation}
\label{eq:reduced_model}
\begin{bmatrix}
P_{aa} & \empty & \empty\\
P_{ba} & P_{bb} & \empty\\
\empty& P_{cb} & P_{cc}
\end{bmatrix}
\end{equation}
#+end_latex

** Asymptotic analysis                                               :PASS1:

The change in the formulation of the model affects how the size scales
with new event types. Analyzing the space efficiency of this approach,
we can see that in the worst case the system will be fully-connected.
The best case occurs when the system contains no connection between
any components. Formally, the space efficiency of this model is

#+begin_latex
\begin{equation}
\begin{split}
\label{eq:reduced_asymp}
model(n) &\in O(n^2)\\
model(n) &\in \Omega(n)
\end{split}
\end{equation}
#+end_latex

** Experimental results                                              :PASS1:

The same methodology presented in section
\ref{subsubsec:experiment_methodology} was used to evaluate the
connection-based model approach. Table \ref{tbl:reduced} shows the
results from the experiments. What can be seen from the results is
that this approach cannot detect faults. When analyzing the model
against the score calculation this makes sense. The score is
calculated when a message event is received but because the model only
contains distributions for message events originating from the publishing
component and the message events which the publishing component subscribes
to, it has a limited capacity to notice that message events are no
longer occurring. Consider the example presented in figure
\ref{fig:simple}: if component /B/ were to die, no more messages
events from components /B/ or /C/ would ever be published. The only
message events which could generate scores would be the messages from
component /A/. If component /A/ is publishing according to the model,
the score would remain high for that message event and this the entire
system. The failure of this approach was the impetus to try the
approach presented in the following section.

#+caption: Experimental results from the connection-based model.
#+attr_latex: align=|l|r|r|r|r|
#+label: tbl:reduced
|---------------+-------------+-------------+-------+----------|
|               | Sensitivity | Specificity |   MCC | Delay    |
|---------------+-------------+-------------+-------+----------|
| Linear        |        0.00 |        0.99 | -0.05 | -        |
|---------------+-------------+-------------+-------+----------|
| Parallel      |        0.00 |        0.95 | -0.18 | -        |
|---------------+-------------+-------------+-------+----------|
| Non-connected |        0.06 |        1.00 |  0.11 | 207 sec. |
|---------------+-------------+-------------+-------+----------|

* Metronome-based approach                                            :PASS1:
** Idea & Implementation                                             :PASS1:

After the failure of the connection-based approach to reduce the model
and remain performant, a new approach had to be created. What was
created was based on the idea of a metronome and how it ticks at a
constant rate. This was mimicked in CAST by creating a component which
published at a constant rate. By learning how every other component
published relative to the metronome component, it was thought that it
might be possible to dramatically reduce the model size while still
remaining performant.

Implementation of this idea meant adding an extra component in the
CAST system and pruning all distributions which did not have the
metronome =m= in the $j$ position of a distribution $P_{ij}$.
Performing this optimization example shown in figure \ref{fig:simple}
resulted in a model $\mathcal{M}$ reduced to

#+begin_latex
\begin{equation}
\label{eq:metronome_model}
\begin{bmatrix}
P_{am} & P_{bm} & P_{cm} & P_{mm}
\end{bmatrix}
\end{equation}
#+end_latex

** Asymptotic analysis                                               :PASS1:

Implementing this technique resulted in a far smaller model. Formally,
the space efficiency of this new model became

#+begin_latex
\begin{equation}
\label{eq:metronome_asymp}
model(n) \in \Theta(n + 1)
\end{equation}
#+end_latex

This difference results in a rather dramatic reduction. For example,
on complex CAST system with 100 components, the model size for the
original implementation would be $model(n) \in \Theta(n^2) = 10,000$.
With the metronome approach, the space efficiency for this same system
becomes $model(n) \in \Theta(n + 1) = 101$. The difference in space
efficiency means that the metronome approach could scale more than the
original implementation.

** Experimental results                                              :PASS1:

#+caption: Experimental results from the metronome model.
#+attr_latex: align=|l|r|r|r|r|
#+label: tbl:metronome
|---------------+-------------+-------------+------+----------|
|               | Sensitivity | Specificity |  MCC | Delay    |
|---------------+-------------+-------------+------+----------|
| Linear        |        0.84 |         1.0 | 0.83 | 6.5 sec. |
|---------------+-------------+-------------+------+----------|
| Parallel      |        0.95 |        0.76 | 0.73 | 1.8 sec. |
|---------------+-------------+-------------+------+----------|
| Non-connected |        0.94 |        0.95 | 0.88 | 9.2 sec. |
|---------------+-------------+-------------+------+----------|

Using the same methodology from section
\ref{subsubsec:experiment_methodology}, experiments were conducted to
analyze the performance of the metronome-based model. Table
\ref{tbl:metronome} summarizes the results. It can be seen that in all
cases this system takes longer to detect faults. Given the massive
reduction in model size, the trade-off is likely worth the increased
delay. It is also the case the sensitivity, specificity, and the
Matthews correlation coefficient suffer from this change in the model.
Given that the only change in the system is the formulation of the
model, it is worth investigating if changes to the score and threshold
calculation algorithms could make this approach more performant while
maintaining the reduced model size.

* Project management                                                  :PASS1:
\label{sec:management}

Large projects are strenuous. Effective project management then
becomes crucial in ensuring constant progress throughout the whole
academic year. This section briefly mentions software and techniques
that were chosen for development.

Git was used rather than Subversion for one key reason: it is easy to
maintain multiple branches of the code and move changes to all of
them. This feature was especially important because it meant that
multiple model implementations could be kept in separate branches,
allowing code to remain clear. In Subversion, doing the equivalent
would have made it very difficult to make updates to all branches when
bugs were found and fixed.

Because inheriting such a large code-base can be overwhelming, unit
tests were used to create a contract of behavior for the most critical
classes in the system. And by using Jenkins as a continuous
integration server, it was possible to know when any change to the
code caused a test on any branch to fail. Jenkins also published the
results of static analysis run by Maven, the build system used. Static
analysis helped suss out potential bugs and resulted in more robust
code. Maven also has the benefit that rather than managing
dependencies myself, it would download from its servers many of the
libraries needed during development. It was not always possible
to download these libraries but they were trivial to install in the
local Maven repository.

Perhaps the most important aspect of project management, and
unfortunately discovered only towards the end of the project, was
issue management. Using Github Issues, it was possible to set project
milestones and attach the tasks necessary to complete the milestone.
This has the benefit of putting in concrete terms the steps necessary
to reach a goal. So rather than flailing around to figure out what to
do next, there was always a concrete task that could be done.

* Project evaluation                                                  :PASS1:
\label{sec:evaluation}

This section will focus on evaluating two important aspects of a
project. First, it will evaluate how well the project met its intended
goals. Second, it will evaluate my performance during the course of
this project. For both aspects, things done right will be mentioned as
will areas of improvement for future projects.

The original goals of the project were to modify the code used by
Raphael Golombek, author of the original approach, to work with CAST
and then to determine its efficacy in this system. These goals were
met with enough time to extend the original approach in a meaningful
way.

During the project, I had the habit of wanting to discard an approach
if I did not get the desired results immediately. This fatalistic
approach to science inhibits the discovery of all but the most trivial
new knowledge. Additionally, I had the bad habit of accepting any of
the data that came out of the system without understanding why those
results had occurred. Fortunately, my supervisor helped me start
to break these habits. Because he would ask me to explain why I had
the results I had, I was forced to sit and analyze the system. By
doing this I was able to find and fix a number of bugs in the original
implementation and correct errors in the score calculation which did
not match the papers describing the technique. I am very grateful to
have to learned these lessons early in my science career.

I also did a lot of things right during the project. As covered in
section \ref{sec:management}, I did a lot to ease the management and
understanding of such a large, experimental code base. Adding unit
tests to the core classes ensured that my alternative model
formulations could not break the code base in unexpected ways. I also
managed my time well. Knowing that the autumn term would be incredibly
busy, I finished the core of my project over the summer holiday. This
eased the stress I would have otherwise felt and let me focus on that
term's work.

Overall, I did a lot right which made the project easier than it could
have been. I also learned a lot about how to approach the scientific
aspects of the project.

* Conclusion                                                          :PASS1:

This dissertation presented the theory behind a new data-driven
technique for detecting faults in event-based robotics middlewares. It
learns a model of the predicted timespan between the publication all
pairs of event types. By exploiting this model, a score for a live
system can be calculated which can be used to classify the robot as
being either in a normal or faulty state. The original implementation
was heavily modified to work with a different middleware than
initially designed and experimental results for this system were
presented. Asymptotic analysis provided motivation for the need to
reduce the size of this learned model. Two alternative model
formulations were shown with experimental results and asymptotic
analysis. Experimentation showed one approach failed to work and so
was discarded. Future work on this topic could incorporate multiple
models to increase flexibility. Additionally, models could be learned
against known faults which the robot could utilize to perform specific
actions for graceful degradation. This project took a lot of effort
but was well worth it for the knowledge gained.

\newpage
\bibliographystyle{plain}
\bibliography{references}


\appendix\appendixpage\addappheadtotoc
* Experiment graphs                                                   :PASS1:
\label{appendix:graphs}
** Original model
*** Linear chain

#+begin_center
[[file:img/original_linear.eps]]
#+end_center

*** Parallel chains

#+begin_center
[[file:img/original_parallel.eps]]
#+end_center

*** Non-connected components

#+begin_center
[[file:img/original_nonconnected.eps]]
#+end_center

** Connection-based model
*** Linear chain

#+begin_center
[[file:img/reduced_linear.eps]]
#+end_center

*** Parallel chains

#+begin_center
[[file:img/reduced_parallel.eps]]
#+end_center

*** Non-connected components

#+begin_center
[[file:img/reduced_nonconnected.eps]]
#+end_center

** Metronome model
*** Linear chain

#+begin_center
[[file:img/metronome_linear.eps]]
#+end_center

*** Parallel chains

#+begin_center
[[file:img/metronome_parallel.eps]]
#+end_center

*** Non-connected components

#+begin_center
[[file:img/metronome_nonconnected.eps]]
#+end_center

* User guide                                                          :DRAFT:
** Installation

As this project depends on Java and CAST, you must have a system which
can run both. A working installation of CAST is necessary;
instructions can be found on the project homepage [fn:1]. Once CAST is
installed, most of the prerequisites will be met.

Additionally, this project uses Apache Maven as its build system. This
has the benefit that most libraries are automatically installed from a
remote repository with no work on your part. Unfortunately, not all
of the necessary Java libraries are available in the Maven
repositories so in addition, there is a top-level folder called =lib=
which contains additional libraries. These should be installed to the
local Maven repository by standard means. Documentation for performing
this can be seen by running =mvn help install= at the command prompt.

With of all the necessary preconditions met, building the project
should be simple. To build the project into a =jar=, simply go to
top-level folder in the project and execute the following command

#+begin_example
  user@machine:~/fyp$ mvn package
#+end_example

This command will compile the code, run all of the unit tests, and
then build the =jar= file.

** Running

#+begin_example
    user@machine:~/fyp$ java -Xmx2g \
                        -jar \
                        target/aucom-0.0.1-jar-with-dependencies.jar
#+end_example

The following command line options are available for determine which
part of the system you would like to run. 

#+begin_example 
  java AucomMain [options...]
   -C         : Run the data collector. This must be used with
                the -o options to specify the name of the
                output file
   -D         : Transform a classification file into a dat file
                suitable for graphing in gnuplot.
   -E         : Run the data collector. This must be used with
                the -i and -o options to specify the name of
                the input and output files
   -R         : Run aucom with a previously collected
                observationfiles as the input.
   -e N       : The observation when the error is to occur.
   -i FILE    : *Required* The input file. Given the major mode
                of the program, the type of file will be
                inferred.
   -o FILE    : *Required* The output file. Given the major
                mode of the program, the type of file will be
                inferred.
   -q         : Inhibit output, with the exception of the fault
                timestamp when running an experiment.
   -s N       : The number of observations to collect before
                terminating the program.
   -t FILE    : The file to use when training the model for
                replay mode.
#+end_example

Because it can be so tedious to specify Java VM options and options
for the fault detector, there are a serious of wrapper scripts to make
it more bearable. These can be found in the directory
=experiment_configs=. The script =observation_collection.sh= creates a
run with the necessary components to collect an input observation stream
for training, the script =experiment.sh= will run an experiment, and
the script =convert.sh= will convert from the default classification
XML data to a space separated CSV file for easier plotting. There is
an additional script, =replay.sh=, which allows one to run an entire
experiment independent of CAST. All that is needed are two observation
time series; one is used as the training data and the other used as
input to the trained fault detector.

** Analysis

Analysis is an important aspect of this project so a lot of work has
been done to make it as quick as possible. As a result, data comes out
of the system in a format easily interpreted by the =gnuplot=. This
has been the program used for plotting data throughout this project
and there are a number of example scripts scattered through the
project directories. A simple =gnuplot= script is presented below which will
display the graph to the screen. 

#+begin_example
  reset
  set yrange [0:1]
  data='experimental_data.csv'
  plot data using 1:2 with lines title 'Score',\
       data using 1:3 with lines title 'Threshold'
#+end_example

To generate the plot, run the script with the command below making
sure you enter the =-p= to persist the window after the script terminates.

#+begin_example
  gnuplt -p analysis.plt
#+end_example

More options can be found in the manpages or in the excellent online
documentation [fn:2].

* Directory Structure

The folder contains two separate projects. One project, =aucom.sa=, is
the set of CAST components required to communicate with the fault
detector and run experiments. The folder =aucom= contains the bulk of
the work. It contains the modified source based on the original
implementation. 

The structure of the =aucom= project is based on a standard Maven
project with extra directories for experimental configurations and the
dissertation. The folder =cast_configs= contains all of the CAST
scripts to run the experimental setups. The folder
=experiment_configs= contains the wrapper scripts to ease running
experiments. The =docs= folder contains this dissertation and proposal
in \LaTeX{} form.

Additionally, the =src= folder of each of three model formulations is
provided. If more up-to-date versions are desired, they can be found
in the project repository [fn:3].

* Graphs                                                           :NOEXPORT:
** Original
*** Linear

#+begin_src gnuplot :var data="./data/original_3chain_fault.csv" :exports none :file "img/original_linear.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:150000]
  set format x "%3.0f"
  set key below
  fault = 255#255673
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[857ecf0ba9b830ab8504247a9f41f5de22748601]:
[[file:img/original_linear.eps]]

*** Parallel

#+begin_src gnuplot :var data="./data/original_4x4_fault.csv" :exports none :file "img/original_parallel.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  set xrange [0:120]
  set format x "%3.0f"
  set key below
  fault = 51#51878
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[42d138abeea0f0e70706b50f7600dc73fa81be66]:
[[file:img/original_parallel.eps]]

*** Non-connected

#+begin_src gnuplot :var data="./data/original_10x1_fault.csv" :exports none :file "img/original_nonconnected.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 101#101500
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[e7af16506a2820b6664d748d1e20cb0b60cb7e73]:
[[file:img/original_nonconnected.eps]]


*** 4x4 normal

#+begin_src gnuplot :var data="./data/original_4x4_normal.csv" :exports none :file "img/original_4x4_normal.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set yrange [0:1]
  set xrange [0:150000]

  set title 'Normal'
  plot norm using 1:2 with dots notitle,\
       norm using 1:2 with lines smooth bezier title 'Score (smoothed)',\
       norm using 1:3 with lines title 'Threshold'
#+end_src

#+RESULTS[712afaa890dd2a697fe7b6fcc85e9d8f3528686f]:
[[file:img/original_4x4_normal.eps]]

*** 4x4 fault

#+begin_src gnuplot :var data="./data/original_4x4_fault.csv" :exports none :file "img/original_4x4_fault.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set yrange [0:1]
  set xrange [0:150000]
  set title "Normal"
  plot data using 1:2 with dots notitle,\
       data using 1:2 with lines smooth bezier title 'Score (smoothed)',\
       data using 1:3 with lines title 'Threshold'
#+end_src
#+RESULTS[43081e236f08b1ee98a8982967e878c0ad9f7e27]:
[[file:img/original_4x4_fault.eps]]

** Reduced
*** Linear

#+begin_src gnuplot :var data="./data/reduced_3chain_fault.csv" :exports none :file "img/reduced_linear.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 102
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[bbab97be2f7ea32a6fbe7de3afc7a86be64cac84]:
[[file:img/reduced_linear.eps]]

*** Parallel

#+begin_src gnuplot :var data="./data/reduced_4x4_fault.csv" :exports none :file "img/reduced_parallel.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 64
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[309ac14f19a2ef08284781a59e6f7c9dcf0f54cf]:
[[file:img/reduced_parallel.eps]]

*** Non-connected

#+begin_src gnuplot :var data="./data/reduced_10x1_fault.csv" :exports none :file "img/reduced_nonconnected.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 101
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[4f08cfd84807207fb83a60dd47b6c7cd6a2f36a0]:
[[file:img/reduced_nonconnected.eps]]

** Metronome
*** Linear

#+begin_src gnuplot :var data="./data/metronome_3chain_fault.csv" :exports none :file "img/metronome_linear.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 21
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[221fb4a4721c1723807b78c23d92405a24ef1ea2]:
[[file:img/metronome_linear.eps]]

*** Parallel

#+begin_src gnuplot :var data="./data/metronome_4x4_fault.csv" :exports none :file "img/metronome_parallel.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 18
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[e9b29ec59f1b19cd4b6af0fd6491894c38c92cc6]:
[[file:img/metronome_parallel.eps]]

*** Non-connected

#+begin_src gnuplot :var data="./data/metronome_10x1_fault.csv" :exports none :file "img/metronome_nonconnected.eps" :cache yes
  reset
  set terminal postscript color solid eps enhanced 20
  set parametric
  set yrange [0:1]
  set ylabel 'Score'
  set y2label 'Threshold'
  set xlabel 'Seconds'
  #set xrange [0:200]
  set format x "%3.0f"
  set key below
  fault = 93
  plot data using ($1/1000):($2) with lines  title 'Score',\
       data using ($1/1000):($3) with lines title 'Threshold',\
       fault, t title 'Induced fault'
#+end_src

#+results[c1414d7a1aaba8ba6ea10939296f50127b5e511e]:
[[file:img/metronome_nonconnected.eps]]

* Dot                                                              :NOEXPORT:
** Simple example

#+begin_src dot :exports none :file "img/simple.pdf" :cache yes
  digraph Example1 {
  rankdir=LR;
  subgraph cluster2 {
  label="Event from B";
  A3[label="A"];
  B3[label="B"];
  C3[label="C"];
  A3 -> B3
  [label="a  "];
  B3 -> C3
  [label="b  (150ms)",color="red",style="bold",fontcolor="red"];

  }
  subgraph cluster1 {
  label="Event from A";
  A2[label="A"];
  B2[label="B"];
  C2[label="C"];
  A2 -> B2
  [label="a  (100ms)",color="red",style="bold",fontcolor="red"];
  B2 -> C2 [label="b  "];
  }
  subgraph cluster0 {
  label="No event";
  A1[label="A"];
  B1[label="B"];
  C1[label="C"];
  A1 -> B1 [label="a  "];
  B1 -> C1 [label="b  "];
  }
  }
#+end_src

#+results[28b705f07d1e03abb305d766c3977c98ea4a8c35]:
[[file:img/simple.pdf]]

** Complex example

#+begin_src dot :exports none :file "img/complex.pdf" :cache yes
  digraph real {
  rankdir=LR;
  A -> B [dir="both"];
  A -> C [dir="both"];
  A -> D [dir="both"];
  A -> E [dir="both"];
  A -> F [dir="both"];
  B -> E;
  C -> D;
  D -> E;
  F -> D;
  }
#+end_src

#+results[99f3dcb61f89218e0549f24db3818522474e40b1]:
[[file:img/complex.pdf]]

** Learned

#+begin_src dot :exports none :file "img/learned.pdf" :cache yes
  digraph G {
          rankdir=LR;
          A -> A [label="P(AA)"];
          A -> B [label="P(AB)"];
          A -> C [label="P(AC)"];
          B -> A [label="P(BA)"];
          B -> B [label="P(BB)"];
          B -> C [label="P(BC)"];
          C -> A [label="P(CA)"];
          C -> B [label="P(CB)"];
          C -> C [label="P(CC)"];
  }
#+end_src

#+results[cc2bb741e8fa3d5e6be7049aa932a42ec96640c5]:
[[file:img/learned.pdf]]

** FTS graph

#+begin_src dot :exports none :file "img/fts.pdf" :cache yes
  digraph G {
  CAST;
  CalcScore [label="Calculate Score"];
  ClassifyScore [label="Classify"];
  CAST -> Encode -> CalcScore -> ClassifyScore;
  ClassifyScore -> CAST [style="dotted"];
  }
#+end_src

#+results[5710aa41772addb6164eb3ba5522bf326d7464ce]:
[[file:img/fts.pdf]]

#  LocalWords:  Virtualization subarchitecture timespan suboptimal
** 10x0 system
#+begin_src dot :exports none :file "img/10x0.pdf" :cache yes
  graph G {
          A;
          B; C; D; E; F; G; H; I; J;
  }
#+end_src

#+results[b8b5f54062138b16fa109b193bbe3784095243ef]:
[[file:img/10x0.pdf]]

** 4x4 system

#+begin_src dot :exports none :file "img/4x4.pdf" :cache yes
digraph four_chain {
          rankdir=LR;
          A -> B -> C -> D;
          E -> F -> G -> H;
          I -> J -> K -> L;
          M -> N -> O -> P;
}
#+end_src

#+results[102e7bb2e2a92621d961c874d899b77a207c512b]:
[[file:img/4x4.pdf]]

** Dora

#+begin_src dot :exports none :file "img/dora.pdf" :cache yes
digraph four_chain {
          rankdir=LR;
          A -> B -> C -> D;
          E -> F -> G -> H;
          I -> J -> K -> L;
          M -> N -> O -> P;
}
#+end_src

#+results[9256b7f8aa8b1fdab31ab3f2e0eec2527c138cb7]:
[[file:img/dora.pdf]]

#  LocalWords:  analytical middleware performant metadata runtime

* Footnotes

[fn:1] [[http://www.cs.bham.ac.uk/research/projects/cosy/cast]]
[fn:2] [[http://www.gnuplot.info/docs_4.6]]
[fn:3] [[https://github.com/jvia/fyp]]

#  LocalWords:  Autosub
