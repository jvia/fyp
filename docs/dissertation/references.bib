@article{Antonelo2008,
  abstract =     {Reservoir Computing (RC) techniques use a fixed
                  (usually randomly created) recurrent neural network,
                  or more generally any dynamic system, which operates
                  at the edge of stability, where only a linear static
                  readout output layer is trained by standard linear
                  regression methods. In this work, RC is used for
                  detecting complex events in autonomous robot
                  navigation. This can be extended to robot
                  localization tasks which are solely based on a few
                  low-range, high-noise sensory data. The robot thus
                  builds an implicit map of the environment (after
                  learning) that is used for efficient localization by
                  simply processing the input stream of distance
                  sensors. These techniques are demonstrated in both a
                  simple simulation environment and in the physically
                  realistic Webots simulation of the commercially
                  available e-puck robot, using several complex and
                  even dynamic environments.},
  author =       {Antonelo, E a and Schrauwen, B and Stroobandt, D},
  doi =          {10.1016/j.neunet.2008.06.010},
  file =         {:Users/jxv911/Documents/Mendeley Desktop/Antonelo,
                  Schrauwen, Stroobandt/Neural networks the official
                  journal of the International Neural Network
                  Society/Antonelo, Schrauwen, Stroobandt - 2008 -
                  Event detection and localization for small mobile
                  robots using reservoir computing.pdf:pdf},
  issn =         {0893-6080},
  journal =      {Neural networks : the official journal of the
                  International Neural Network Society},
  keywords =     {Automated,Computer Simulation,Environment,Neural
                  Networks (Computer),Pattern Recognition,Robotics},
  month =        aug,
  number =       6,
  pages =        {862--71},
  pmid =         18662855,
  publisher =    {Elsevier},
  title =        {{Event detection and localization for small mobile
                  robots using reservoir computing.}},
  url =          {http://www.ncbi.nlm.nih.gov/pubmed/18662855},
  volume =       21,
  year =         2008
}

@article{Golombek2011,
  author =       {Golombek, Raphael and Wrede, Sebastian and Hanheide,
                  Marc and Heckmann, Martin},
  journal =      {Computer},
  title =        {{On-line Data-Driven Fault Detection for Robotic
                  Systems}},
  year =         2011
}

@article{Jaeger2004,
  abstract =     {We present a method for learning nonlinear systems,
                  echo state networks (ESNs). ESNs employ artificial
                  recurrent neural networks in a way that has recently
                  been proposed independently as a learning mechanism
                  in biological brains. The learning method is
                  computationally efficient and easy to use. On a
                  benchmark task of predicting a chaotic time series,
                  accuracy is improved by a factor of 2400 over
                  previous techniques. The potential for engineering
                  applications is illustrated by equalizing a
                  communication channel, where the signal error rate
                  is improved by two orders of magnitude.},
  author =       {Jaeger, Herbert and Haas, Harald},
  doi =          {10.1126/science.1091277},
  file =         {:Users/jxv911/Documents/Mendeley Desktop/Jaeger,
                  Haas/Science (New York, N.Y.)/Jaeger, Haas - 2004 -
                  Harnessing nonlinearity predicting chaotic systems
                  and saving energy in wireless communication.pdf:pdf},
  issn =         {1095-9203},
  journal =      {Science (New York, N.Y.)},
  month =        apr,
  number =       5667,
  pages =        {78--80},
  pmid =         15064413,
  title =        {{Harnessing nonlinearity: predicting chaotic systems
                  and saving energy in wireless communication.}},
  url =          {http://www.ncbi.nlm.nih.gov/pubmed/15064413},
  volume =       304,
  year =         2004
}

@article{Maier2000,
  abstract =     {Artificial Neural Networks (ANNs) are being used
                  increasingly to predict and forecast water resources
                  variables. In this paper, the steps that should be
                  followed in the development of such models are
                  outlined. These include the choice of performance
                  criteria, the division and pre-processing of the
                  available data, the determination of appropriate
                  model inputs and network architecture, optimisation
                  of the connection weights (training) and model
                  validation. The options available to modellers at
                  each of these steps are discussed and the issues
                  that should be considered are highlighted. A review
                  of 43 papers dealing with the use of neural network
                  models for the prediction and forecasting of water
                  resources variables is undertaken in terms of the
                  modelling process adopted. In all but two of the
                  papers reviewed, feedforward networks are used. The
                  vast majority of these networks are trained using
                  the backpropagation algorithm. Issues in relation to
                  the optimal division of the available data, data
                  pre-processing and the choice of appropriate model
                  inputs are seldom considered. In addition, the
                  process of choosing appropriate stopping criteria
                  and optimising network geometry and internal network
                  parameters is generally described poorly or carried
                  out inadequately. All of the above factors can
                  result in non-optimal model performance and an
                  inability to draw meaningful comparisons between
                  different models. Future research efforts should be
                  directed towards the development of guidelines which
                  assist with the development of ANN models and the
                  choice of when ANNs should be used in preference to
                  alternative approaches, the assessment of methods
                  for extracting the knowledge that is contained in
                  the connection weights of trained ANNs and the
                  incorporation of uncertainty into ANN models.},
  author =       {Maier, Holger R. and Dandy, Graeme C.},
  doi =          {10.1016/S1364-8152(99)00007-9},
  file =         {:Users/jxv911/Documents/Mendeley Desktop/Maier,
                  Dandy/Environmental Modelling \& Software/Maier,
                  Dandy - 2000 - Neural networks for the prediction
                  and forecasting of water resources variables a
                  review of modelling issues and applications.pdf:pdf},
  issn =         13648152,
  journal =      {Environmental Modelling \& Software},
  keywords =     {artificial neural networks,forecasting,model
                  development,modelling
                  process,prediction,review,water resources},
  month =        jan,
  number =       1,
  pages =        {101--124},
  title =        {{Neural networks for the prediction and forecasting
                  of water resources variables: a review of modelling
                  issues and applications}},
  url =
                  {http://linkinghub.elsevier.com/retrieve/pii/S1364815299000079},
  volume =       15,
  year =         2000
}

@article{Scherer,
  author =       {Scherer, Stefan and Schwenker, Friedhelm and
                  Campbell, Nick},
  file =         {:Users/jxv911/Documents/Mendeley Desktop/Scherer,
                  Schwenker, Campbell/Discourse/Scherer, Schwenker,
                  Campbell - Unknown - Multi Modal Laughter Detection
                  in Natural Discourses.pdf:pdf},
  journal =      {Discourse},
  keywords =     {echo state networks,gaussian mixture model
                  super,laughter detection,natural discourse,support
                  vector machines,tors,vec-},
  title =        {{Multi Modal Laughter Detection in Natural
                  Discourses}}
}

@inproceedings{Wang2005,
  abstract =     {Traditionally, two protein sequences are classified
                  into the same class if they have high homology in
                  terms of feature patterns extracted through sequence
                  alignment algorithms. These algorithms compare an
                  unseen protein sequence with all the identified
                  protein sequences and returned the higher scored
                  protein sequences. As the sizes of the protein
                  sequence databases are very large, it is a very time
                  consuming job to perform exhaustive comparison of
                  existing protein sequence. Therefore, there is a
                  need to build an improved classification system for
                  effectively identifying protein sequences. In this
                  paper, a recently developed machine learning
                  algorithm referred to as the Extreme Learning
                  Machine (ELM) is used to classify protein sequences
                  with ten classes of super-families downloaded from a
                  public domain database. A comparative study on
                  system performance is conducted between ELM and the
                  main conventional neural network classifier -
                  Backpropagation Neural Networks. Results show that
                  ELMneeds up to four orders of magnitude less
                  training time compared to BP Network. The
                  classification accuracy of ELM is also higher than
                  that of BP network. For given network architecture,
                  ELM does not have any control parameters (i.e,
                  stopping criteria, learning rate, learning epoches,
                  etc) to be manually tuned and can be implemented
                  easily.},
  author =       {Wang, Dianhui and Huang, G.B.},
  booktitle =    {Neural Networks, 2005. IJCNN'05. Proceedings. 2005
                  IEEE International Joint Conference on},
  file =         {:Users/jxv911/Documents/Mendeley Desktop/Wang,
                  Huang/Neural Networks,
                  2005. IJCNN'05. Proceedings. 2005 IEEE International
                  Joint Conference on/Wang, Huang - 2005 - Protein
                  Sequence Classification Using Extreme Learning
                  Machine.pdf:pdf},
  pages =        {1406--1411},
  publisher =    {IEEE},
  title =        {{Protein Sequence Classification Using Extreme
                  Learning Machine}},
  url =
                  {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=1556080},
  volume =       3,
  year =         2005
}
